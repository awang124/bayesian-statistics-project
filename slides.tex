\documentclass[8pt]{beamer}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage{mathrsfs}
\usepackage{mathtools}
\setlength\parindent{0pt}

\title{Spatial Gaussian Process Regression for \\ Bayesian Optical Flow Estimation}
\author{Andy Wang \& Luca Orquiza}
\date{2 December 2025}
\begin{document}
\frame{\titlepage}

\setbeamertemplate{footnote}{%
  \parindent 1em\noindent%
  \raggedright
  \insertfootnotetext\par%
}

\newcommand{\lb}{\left[}
\newcommand{\lp}{\left(}
\newcommand{\rp}{\right)}
\newcommand{\rb}{\right]}
\newcommand{\lr}{\left\{}
\newcommand{\rr}{\right\}}
\newcommand{\cov}{\text{Cov}}
\newcommand{\mle}{\text{MLE}}
\newcommand{\bm}{\boldsymbol{\mu}}
\newcommand{\blankline}{\\\phantom{}\\}
\renewcommand{\vec}{\boldsymbol}

\begin{frame}{Motion in Image Sequences}
\begin{center}
\includegraphics[totalheight=3.0cm]{~/Documents/sem4/mia/proj/img/3.png}
\end{center}
Given two sequential images $I:\mathcal{D}\times[0,T]\to\mathcal{R}$, i.e. \[I(x,y,t)\text{ and }I(x,y,t+\delta t)\] (for fixed $t$ and $\delta t$), the optical flow at time $t$ is a vector field \[\vec{f}(x,y,t)=\lp u(x,y,t),v(x,y,t)\rp\] that transforms one image into the next: \[I\lp x+u(x,y,t),y+v(x,y,t),t+\delta t\rp\simeq I(x,y,t)\]
\footnotetext{Barron, J. L., Fleet, D. J., \& Beauchemin, S. S. (1994). Performance of Optical Flow Techniques. \textit{International Journal of Computer Vision, 12}(1), 43-77.}
\end{frame}

\begin{frame}{Lucas-Kanade Method}
Brightness constancy assumption: \[\frac{d}{dt}I(x(t),y(t),t)=\frac{\partial I}{\partial x}u+\frac{\partial I}{\partial y}v+\frac{\partial I}{\partial t}=0,\quad u\coloneq\frac{dx}{dt},v\coloneq\frac{dy}{dt}\] Underdetermined, so assume same $(u(x,y),v(x,y))\ \forall(x,y)\in W$: \[\underbrace{\begin{bmatrix}I_x(x_1,y_1)&I_y(x_1,y_1)\\\vdots&\vdots\\I_x(x_n,y_n)&I_y(x_n,y_n)\end{bmatrix}}_{\vec{\nabla I}^T}\underbrace{\begin{bmatrix}u\\v\end{bmatrix}}_{\vec{f}}=\underbrace{\begin{bmatrix}-I_t(x_1,y_1)\\\vdots\\-I_t(x_n,y_n)\end{bmatrix}}_{-\vec{I_t}}\] Overdetermined: least squares solution is $\vec{v}=\lp\vec{A}^T\vec{A}\rp^{-1}\vec{A}^T\vec{b}$: \[\begin{bmatrix}u\\v\end{bmatrix}=\begin{bmatrix}\sum I_x(x_i,y_i)^2&\sum I_x(x_i,y_i)I_y(x_i,y_i)\\\sum I_x(x_i,y_i)I_y(x_i,y_i)&\sum I_y(x_i,y_i)^2\end{bmatrix}^{-1}\begin{bmatrix}-\sum I_x(x_i,y_i)I_t(x_i,y_i)\\-\sum I_y(x_i,y_i)I_t(x_i,y_i)\end{bmatrix}\] Optional weighting of pixels via diagonal matrix $\vec{W}$: \[\vec{v}=\lp\vec{A}^T\vec{WA}\rp^{-1}\vec{A}^T\vec{Wb}\]
\footnotetext{Lucas, B. D., \& Kanade, T. (1981). An Iterative Image Registration Technique with an Application to Stereo Vision. \textit{7th International Joint Conference on Artificial Intelligence, 2}, 674-679.}
\end{frame}

\begin{frame}{Lucas-Kanade Results}
\begin{center}\includegraphics[totalheight=3.0cm]{img/yosemite.png}\\\includegraphics[totalheight=5.0cm]{img/lucas-kanade.png}\end{center}
\footnotetext{Barron, J. L., Fleet, D. J., \& Beauchemin, S. S. (1994). Performance of Optical Flow Techniques. \textit{International Journal of Computer Vision, 12}(1), 43-77.}
\end{frame}

\begin{frame}{Probabilistic Motivation}
Classical methods produce deterministic point estimates. \\ Uncertainty is inherent in optical flow estimation, due to:
\begin{itemize}
\item Image noise
\item Brightness changes
\item Low contrast regions
\item Object occlusion
\item Aperture problem
\item Incompatible motions in localized regions
\end{itemize}
Quantification of confidence is desirable for safety-critical aplications, e.g.:
\begin{itemize}
\item Autonomous navigation
\item Computer-integrated surgery
\item Real-time surveillance
\end{itemize}
\end{frame}

\begin{frame}{Review of Flow Methods}
Existing deterministic optical flow methods include:
\begin{itemize}
\item Lucas \& Kanade (1981): previously described.
\item Horn \& Schunck (1981): estimate optical flow by minimizing a global energy functional (with smoothness regularizer) via calculus of variations.
\item FlowNet (Dosovitskiy et al., 2015) use an encoder-decoder CNN (encoder captures low-level semantic motion, decoder restores spatial resolution).
\end{itemize}
Existing probabilistic optical flow methods include:
\begin{itemize}
\item Simoncelli et al. (1991) model brightness constraint errors with Gaussian noise and derive a posterior flow distribution whose mean gives a regularized gradient-based flow estimate.
\item Roy \& Govindu (2000) formulate optical flow as a Markov Random Field labeling problem, solve it via graph cuts on angle and magnitude parameters.
\item Wannenwetsch et al. (2017) perform variational inference on an energy-based model using mean-field approximation to predict optical flow and uncertainty as entropy of the variational distribution.
\end{itemize}
\end{frame}

\begin{frame}{Wang-Orquiza Method}
Suppose $\vec{y}=\vec{A}\vec{x}+\vec{\eta}$, $\vec{A}$ fixed, $\vec{x}$ fixed unknown, $\vec{y}$ observed, $\vec{\eta}\sim\mathcal{N}(\vec{0},\vec{H})$: \[\hat{\vec{x}}_{\mle}(\vec{y})=\arg\max_{\vec{x}}f_{\vec{y}}(\vec{y}|\vec{x})=\arg\max_{\vec{x}}f_{\vec{\eta}}(\vec{y}-\vec{A}\vec{x})=\vec{\Sigma}_{\hat{\vec{x}}}\vec{A}^T\vec{H}^{-1}\vec{y}\] \[\vec{\Sigma}_{\hat{\vec{x}}}=\cov[\hat{\vec{x}}_{\mle}(\vec{y})-\vec{x}]=(\vec{A}^T\vec{H}^{-1}\vec{A})^{-1}\] Same assumptions as Lucas-Kanade, plus additive Gaussian noise: \[\vec{I_t}=-\vec{\nabla I}^T\vec{f}+\vec{\eta}\qquad\vec{\eta}\sim\mathcal{N}(\vec{0},\vec{H})\] Results above give: \[\hat{\vec{f}}=-\vec{\Sigma}_{\hat{\vec{f}}}\vec{\nabla I}\vec{H}^{-1}\vec{I}_t\qquad\vec{\Sigma}_{\hat{\vec{f}}}=(\vec{\nabla I}\vec{H}^{-1}\vec{\nabla I}^T)^{-1}\] Poor texture around $\vec{x}$ $\implies$ small $\nabla I$ $\implies$ large $\vec{\Sigma}_{\hat{\vec{f}}}$.
\end{frame}

\begin{frame}{Wang-Orquiza Results}
\begin{center}\includegraphics[totalheight=2.5cm]{img/yosemite.png}\end{center}
\begin{center}\includegraphics[totalheight=2.5cm]{img/wang-orquiza.png}\end{center}
\end{frame}

\begin{frame}{Spatial Gaussian Processes}
2-dimensional Gaussian process (distribution over functions of 2D inputs): \[\vec{f}(\cdot)=\begin{bmatrix}u(\cdot)\\v(\cdot)\end{bmatrix}\sim\mathcal{GP}(\vec{m}(\cdot),\vec{k}(\cdot,\cdot'))\] Example mean \& covariance kernel (affine \& RBF): \[\vec{m}(\cdot)=\vec{A}(\cdot)+\vec{b},\ \vec{k}(\cdot,\cdot')=\exp\lp-\frac{\|\cdot-\cdot'\|^2}{2\lambda^2}\rp\vec{\Sigma}\] Joint distribution of function values at finite subset of points: \[\begin{bmatrix}\vec{f}(\vec{x}_1)\\\vdots\\\vec{f}(\vec{x}_n)\end{bmatrix}\sim\mathcal{N}\lp\begin{bmatrix}\vec{m}(\vec{x}_1)\\\ddots\\\vec{m}(\vec{x}_n)\end{bmatrix},\begin{bmatrix}\vec{k}(\vec{x}_1,\vec{x}_1)&\cdots&\vec{k}(\vec{x}_1,\vec{x}_n)\\\vdots&\ddots&\vdots\\\vec{k}(\vec{x}_n,\vec{x}_1)&\cdots&\vec{k}(\vec{x}_n,\vec{x}_n)\end{bmatrix}\rp\] Equivalently: \[\vec{F}\coloneq\begin{bmatrix}\vec{U}(\vec{X})\\\vec{V}(\vec{X})\end{bmatrix}\sim\mathcal{N}\lp\bm\coloneq\begin{bmatrix}\bm_u\\\bm_v\end{bmatrix},\vec{K}\coloneq\begin{bmatrix}\vec{K}_{uu}&\vec{K}_{uv}\\\vec{K}_{vu}&\vec{K}_{vv}\end{bmatrix}\rp\]
\end{frame}

\begin{frame}{Gaussian Process Regression}
Through Wang-Orquiza method, we obtain noisy observations $\vec{\tilde{F}}$: \[\vec{\tilde{f}}(\vec{x})=\vec{f}(\vec{x})+\boldsymbol{\eta}(\vec{x}),\ \boldsymbol{H}(\vec{x})\sim\mathcal{N}\lp\vec{0},\vec{\Sigma}_{\tilde{\vec{f}}}\rp\] The noisy distribution is: \[\vec{\tilde{F}}\big|\vec{F}\sim\mathcal{N}\lp\vec{F},\vec{\Sigma}_{\tilde{\vec{f}}}\rp,\ \vec{F}\sim\mathcal{N}\lp\bm,\vec{K}\rp\implies\vec{\tilde{F}}\sim\mathcal{N}\lp\bm,\vec{K}+\vec{\Sigma}_{\tilde{\vec{f}}}\rp\] We want to estimate true optical flows: we form the joint distribution. \[\begin{bmatrix}\vec{F}\\\vec{\tilde{F}}\end{bmatrix}\sim\mathcal{N}\lp\begin{bmatrix}\bm\\\bm\end{bmatrix},\begin{bmatrix}\vec{K}&\vec{K}\\\vec{K}&\vec{K}+\vec{\Sigma}_{\tilde{\vec{f}}}\end{bmatrix}\rp\] We derive the conditional distribution (posterior): \[\vec{F}|\vec{\tilde{F}}\sim\mathcal{N}\lp\bm+\vec{K}\lp\vec{K}+\vec{\Sigma}_{\tilde{\vec{f}}}\rp^{-1}\lp\vec{\tilde{F}}-\bm\rp,\vec{K}-\vec{K}\lp\vec{K}+\vec{\Sigma}_{\tilde{\vec{f}}}\rp^{-1}\vec{K}\rp\] Mean serves as estimate, covariance as uncertainty.
\end{frame}

\begin{frame}{Parameter Fitting}
Mean/covariance parameters (e.g. lengthscale $\lambda^2$) are optimized by maximizing the marginal likelihood of observations $\vec{\tilde{F}}$. This likelihood is: \[p\lp\vec{\tilde{F}}\rp\propto\frac{1}{\sqrt{\det\lp\vec{K}+\vec{\Sigma}_{\tilde{\vec{f}}}\rp}}\exp\lp-\frac{1}{2}\lp\vec{\tilde{F}}-\bm\rp^T\lp\vec{K}+\vec{\Sigma}_{\tilde{\vec{f}}}\vec{I}\rp^{-1}\lp\vec{\tilde{F}}-\bm\rp\rp\] In practice we minimize negative log-likelihood via gradient descent: \[-\log p\lp\vec{\tilde{F}}\rp\propto\frac{1}{2}\lp\vec{\tilde{F}}-\bm\rp^T\lp\vec{K}+\vec{\Sigma}_{\tilde{\vec{f}}}\rp^{-1}\lp\vec{\tilde{F}}-\bm\rp+\frac{1}{2}\det\lp\vec{K}+\vec{\Sigma}_{\tilde{\vec{f}}}\rp\] We minimize this numerically via gradient descent.
\end{frame}

\begin{frame}{Parameter Fitting (cont.)}
Let $\varphi$ be a parameter of $\vec{m},\ \vec{y}=\vec{\tilde{F}}-\bm,\ \vec{K}_y=\vec{K}+\sigma_{\eta}^2\vec{I}$: \[\frac{\partial\mathcal{L}}{\partial\varphi}=\frac{1}{2}\lb\lp\frac{\partial\vec{y}^T}{\partial\varphi}\rp\vec{K}_y^{-1}\vec{y}+\vec{y}^T\vec{K}_y\lp\frac{\partial\vec{y}}{\partial\varphi}\rp\rb=\frac{1}{2}\lp2\vec{y}^T\vec{K}_y\lp\frac{\partial\vec{y}}{\partial\varphi}\rp\rp=-\vec{y}^T\vec{K}_y\lp\frac{\partial\vec{m}}{\partial\varphi}\rp\] Let $\theta$ be a parameter of $\vec{k}$: \[\frac{\partial\mathcal{L}}{\partial\theta}=\vec{y}^T\lp\frac{\partial\vec{K}_y^{-1}}{\partial\theta}\rp\vec{y}+\frac{\partial|\vec{K}_y|}{\partial\theta}=-\frac{1}{2}\vec{y}^T\vec{K}^{-1}\lp\frac{\partial\vec{K}_y}{\partial\theta}\rp\vec{K}^{-1}\vec{y}+\frac{1}{2}\text{tr}\lp\vec{K}_y^{-1}\lp\frac{\partial\vec{K}_y}{\partial\theta}\rp\rp\] RBF parameter $\lambda^2$: \[\frac{\partial\vec{K}_y}{\partial\lambda}=\vec{K}\odot\frac{\|\vec{x}-\vec{x}'\|}{\lambda^3}\]
\end{frame}

\begin{frame}{GP Regression Results}
\begin{center}\includegraphics[totalheight=2.5cm]{img/yosemite.png}\end{center}
\begin{center}\includegraphics[totalheight=2.5cm]{img/gaussian-process.png}\end{center}
\end{frame}

\begin{frame}{Discussion}
Our maximum-likelihood method produced an initial estimate and uncertainty. \blankline Our Gaussian-process Bayesian method provided updated these (posterior), after enforcing a global smoothness constraint (Gaussian process prior). \blankline Possible next steps:
\begin{itemize}
\item Obtain better observations: FlowNet, RAFT, etc.
\item Experiment with more complex covariance kernels.
\item Perform segmentation, smooth each segment independently.
\item Extend to spatiotemporal regression (3D, multiple frames).
\end{itemize}
\end{frame}

\begin{frame}{Appendix (Regarding Our Data)}
Our data for this project is the Yosemite sequence, a well-known benchmark dataset for optical flow problems. It consists of 15 simulated images of Yosemite national park ``taken" by an aerial camera moving in a straight line. It was generated by Lynn Quam at SRI, by taking a topdown image and texture mapping it to a depth map to create a 3D model, with the images generated from a similar camera. Frames 1 (first) and 15 (last) make the camera's motion more apparent. Our image data consists solely of grayscale brightness values at each pixel. No summary statistics are really helpful, and images aren't modeled generatively, but we've included average brightness (with and without the images' top ``sky" section across all 15 frames):
\begin{center}\includegraphics[totalheight=2.5cm]{img/yosemite-first-last.png}\qquad\includegraphics[totalheight=2.5cm]{img/data-boxplot-1.png}\qquad\includegraphics[totalheight=2.5cm]{img/data-boxplot-2.png}\end{center}
\end{frame}
\end{document}

